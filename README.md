ğŸ›¸ Drone Navigation using Reinforcement Learning + AirSim + Next.js
This project demonstrates how to train and deploy a drone navigation agent using Proximal Policy Optimization (PPO) in the AirSim simulator, with a simple Next.js + Flask frontend to interact and test the model.

ğŸš€ Features
ğŸ§  PPO-based Reinforcement Learning (Stable-Baselines3)

ğŸŒ AirSim simulator (Unreal Engine based)

ğŸŒ Next.js frontend + Flask backend API

ğŸ“Š Visual control inputs for live testing

ğŸ“¦ Folder Structure

```bash
drone_project/
â”œâ”€â”€ env/                   # Custom AirSim environment wrapper
â”œâ”€â”€ saved_models/          # Trained PPO models
â”œâ”€â”€ train.py               # Training script
â”œâ”€â”€ evaluate.py            # Evaluation script
â”œâ”€â”€ resume.py              # Resume training from checkpoint
â”œâ”€â”€ serve.py               # Flask API server (for model inference)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ web/                   # Next.js frontend
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ index.js       # Main UI
â”‚   â”‚   â””â”€â”€ api/fly.js     # API proxy to Flask server
â”‚   â”œâ”€â”€ .env.local         # Environment variables (optional)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
âš™ï¸ Setup & Installation
Python (Backend - Flask + AirSim)

Step 1: Clone the repository
git clone https://github.com/shashipreetham18/drone_project.git
cd drone_project

Step 2: Set up virtual environment
python -m venv venv
venv\Scripts\activate (On Windows)
OR
source venv/bin/activate (On Linux/Mac)

Step 3: Install Python dependencies
pip install -r requirements.txt

Step 4: Launch AirSim
Download and open AirSimNH.exe (City or Neighborhood environment).
Make sure the simulator is running before starting the server.

Step 5: Run the backend Flask server
python serve.py

The Flask server runs at: http://127.0.0.1:5000/fly

ğŸŒ Web Frontend (Next.js)
Step 1: Install frontend dependencies
cd web
npm install

Step 2: Run the development server
npm run dev

Then open http://localhost:3000 in your browser.

ğŸ§  How the Model Works
Environment: AirSim 3D simulator

Action Space: 5â€“7 discrete drone actions

Observation Space: Position + Goal vector

Algorithm: PPO (Proximal Policy Optimization)

ğŸ§ª Example Use Flow
Start the Flask server

Open the Next.js frontend

Select position + goal

Model predicts action via Flask

Output shown in UI / simulator

ğŸ›  To Do
 Visual path overlay (map or image)

 Host backend (if needed externally)

 Add collision detection & feedback

 Add support for real drone hardware (future scope)

ğŸ“š Resources
AirSim GitHub: https://github.com/microsoft/AirSim

Stable-Baselines3: https://stable-baselines3.readthedocs.io/

PPO Paper (OpenAI): https://arxiv.org/abs/1707.06347

ğŸ¤ Maintainer
Shashi Preetham (https://github.com/shashipreetham18)

ğŸ License
MIT License
